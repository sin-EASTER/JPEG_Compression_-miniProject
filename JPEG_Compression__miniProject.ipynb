{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04c0d024716f44168c25764f5d2a2904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".jpg,.jpeg,.png,.bmp,.tiff",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_18902f9643a24fa395ee947552174aa4",
            "metadata": [
              {
                "name": "mandril_color.jpg",
                "type": "image/jpeg",
                "size": 537001,
                "lastModified": 1420611234000
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_0cddd6a0413b4aa88ac98a44eec9a75c"
          }
        },
        "18902f9643a24fa395ee947552174aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cddd6a0413b4aa88ac98a44eec9a75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sin-EASTER/JPEG_Compression_-miniProject/blob/main/JPEG_Compression__miniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JPEG Compression**"
      ],
      "metadata": {
        "id": "Vy1QM21kUtb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports necessary libraries for image processing and compression, including numpy for numerical operations, cv2 (OpenCV) for image manipulation, collections.Counter for frequency counting, and math.ceil for ceiling division."
      ],
      "metadata": {
        "id": "aXWu5Nz6zekN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from math import ceil\n",
        "\n",
        "imgOriginal = None"
      ],
      "metadata": {
        "id": "7RTuoEnRaNeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block sets up an interactive file upload widget. It allows you to select an image file (like JPG, PNG, or BMP) from your computer. Once you upload a file, the handle_upload function processes it: it reads the image data, decodes it using OpenCV, and then stores the image in the global imgOriginal variable for use in other parts of the notebook."
      ],
      "metadata": {
        "id": "1cYtoS2VTT2u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "04c0d024716f44168c25764f5d2a2904",
            "18902f9643a24fa395ee947552174aa4",
            "0cddd6a0413b4aa88ac98a44eec9a75c"
          ]
        },
        "id": "eb515b68",
        "outputId": "917dcf00-cabb-47b5-e4b1-160b79b00087"
      },
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Create a FileUpload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='.jpg,.jpeg,.png,.bmp,.tiff',  # Accepted file types\n",
        "    multiple=False  # Allow only one file upload\n",
        ")\n",
        "\n",
        "# Display the uploader widget\n",
        "print(\"Please upload your image file:\")\n",
        "display(uploader)\n",
        "\n",
        "def handle_upload(change):\n",
        "    global imgOriginal # Declare imgOriginal as global\n",
        "    if uploader.value:\n",
        "        # Get the first (and only) uploaded file's content\n",
        "        uploaded_file_name = next(iter(uploader.value))\n",
        "        uploaded_file_content = uploader.value[uploaded_file_name]['content']\n",
        "\n",
        "        # Convert bytes to a numpy array\n",
        "        nparr = np.frombuffer(uploaded_file_content, np.uint8)\n",
        "\n",
        "        # Decode image using OpenCV\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is not None:\n",
        "            imgOriginal = img # Assign the uploaded image to imgOriginal\n",
        "            print(f\"Uploaded image '{uploaded_file_name}' shape: {imgOriginal.shape} and set as imgOriginal.\")\n",
        "        else:\n",
        "            print(f\"Error: Could not decode image '{uploaded_file_name}'. Make sure it's a valid image file.\")\n",
        "\n",
        "# Attach the handler function to the uploader's observe method\n",
        "# The '_counter' traitlet changes when files are added or removed\n",
        "uploader.observe(handle_upload, names='_counter')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your image file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.jpg,.jpeg,.png,.bmp,.tiff', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04c0d024716f44168c25764f5d2a2904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded image 'mandril_color.jpg' shape: (512, 512, 3) and set as imgOriginal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compression"
      ],
      "metadata": {
        "id": "0ffBXClvXy1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the zigzag function, which converts a 2D matrix (like a quantized block of image data) into a 1D array using a zigzag scan pattern. This is a common step in JPEG compression."
      ],
      "metadata": {
        "id": "uvyo5x8g0A8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zigzag(matrix: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    computes the zigzag of a quantized block\n",
        "    :param numpy.ndarray matrix: quantized matrix\n",
        "    :returns: zigzag vectors in an array\n",
        "    \"\"\"\n",
        "    # initializing the variables\n",
        "    h = 0\n",
        "    v = 0\n",
        "    v_min = 0\n",
        "    h_min = 0\n",
        "    v_max = matrix.shape[0]\n",
        "    h_max = matrix.shape[1]\n",
        "    i = 0\n",
        "    output = np.zeros((v_max * h_max))\n",
        "\n",
        "    while (v < v_max) and (h < h_max):\n",
        "        if ((h + v) % 2) == 0:  # going up\n",
        "            if v == v_min:\n",
        "                output[i] = matrix[v, h]  # first line\n",
        "                if h == h_max:\n",
        "                    v = v + 1\n",
        "                else:\n",
        "                    h = h + 1\n",
        "                i = i + 1\n",
        "            elif (h == h_max - 1) and (v < v_max):  # last column\n",
        "                output[i] = matrix[v, h]\n",
        "                v = v + 1\n",
        "                i = i + 1\n",
        "            elif (v > v_min) and (h < h_max - 1):  # all other cases\n",
        "                output[i] = matrix[v, h]\n",
        "                v = v - 1\n",
        "                h = h + 1\n",
        "                i = i + 1\n",
        "        else:  # going down\n",
        "            if (v == v_max - 1) and (h <= h_max - 1):  # last line\n",
        "                output[i] = matrix[v, h]\n",
        "                h = h + 1\n",
        "                i = i + 1\n",
        "            elif h == h_min:  # first column\n",
        "                output[i] = matrix[v, h]\n",
        "                if v == v_max - 1:\n",
        "                    h = h + 1\n",
        "                else:\n",
        "                    v = v + 1\n",
        "                i = i + 1\n",
        "            elif (v < v_max - 1) and (h > h_min):  # all other cases\n",
        "                output[i] = matrix[v, h]\n",
        "                v = v + 1\n",
        "                h = h - 1\n",
        "                i = i + 1\n",
        "        if (v == v_max - 1) and (h == h_max - 1):  # bottom right element\n",
        "            output[i] = matrix[v, h]\n",
        "            break\n",
        "    return output"
      ],
      "metadata": {
        "id": "gyng5dz1uSzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the trim function, which removes trailing zeros from a NumPy array. If the array becomes empty after trimming, it adds a single zero, which is likely used as the DC component in run-length encoding."
      ],
      "metadata": {
        "id": "lsmF25QD0OOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(array: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    in case the trim_zeros function returns an empty array, add a zero to the array to use as the DC component\n",
        "    :param numpy.ndarray array: array to be trimmed\n",
        "    :return numpy.ndarray:\n",
        "    \"\"\"\n",
        "    trimmed = np.trim_zeros(array, 'b')\n",
        "    if len(trimmed) == 0:\n",
        "        trimmed = np.zeros(1)\n",
        "    return trimmed"
      ],
      "metadata": {
        "id": "Ny2myfVpuhXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the run_length_encoding function. It takes zigzagged coefficients and applies run-length encoding (RLE), distinguishing between DC components (represented by (size, amplitude)) and AC components (represented by (run_length, size, amplitude)). It also inserts 'EOB' (End Of Block) markers."
      ],
      "metadata": {
        "id": "0Efk-pqg0Re4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_length_encoding(array: np.ndarray) -> list:\n",
        "    \"\"\"\n",
        "    finds the intermediary stream representing the zigzags\n",
        "    format for DC components is <size><amplitude>\n",
        "    format for AC components is <run_length, size> <Amplitude of non-zero>\n",
        "    :param numpy.ndarray array: zigzag vectors in array\n",
        "    :returns: run length encoded values as an array of tuples\n",
        "    \"\"\"\n",
        "    encoded = list()\n",
        "    run_length = 0\n",
        "    eob = (\"EOB\",)\n",
        "\n",
        "    for i in range(len(array)):\n",
        "        for j in range(len(array[i])):\n",
        "            trimmed = trim(array[i])\n",
        "            if j == len(trimmed):\n",
        "                encoded.append(eob)  # EOB\n",
        "                break\n",
        "            if i == 0 and j == 0:  # for the first DC component\n",
        "                encoded.append((int(trimmed[j]).bit_length(), trimmed[j]))\n",
        "            elif j == 0:  # to compute the difference between DC components\n",
        "                diff = int(array[i][j] - array[i - 1][j])\n",
        "                if diff != 0:\n",
        "                    encoded.append((diff.bit_length(), diff))\n",
        "                else:\n",
        "                    encoded.append((1, diff))\n",
        "                run_length = 0\n",
        "            elif trimmed[j] == 0:  # increment run_length by one in case of a zero\n",
        "                run_length += 1\n",
        "            else:  # intermediary steam representation of the AC components\n",
        "                encoded.append((run_length, int(trimmed[j]).bit_length(), trimmed[j]))\n",
        "                run_length = 0\n",
        "            # send EOB\n",
        "        if not (encoded[len(encoded) - 1] == eob):\n",
        "            encoded.append(eob)\n",
        "    return encoded"
      ],
      "metadata": {
        "id": "cT9iw5ghuoyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the get_freq_dict function, which calculates the frequency of each unique symbol in a given list or array. This frequency table is essential for building Huffman codes."
      ],
      "metadata": {
        "id": "EMGM5E-s0ZxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_freq_dict(array: list) -> dict:\n",
        "    \"\"\"\n",
        "    returns a dict where the keys are the values of the array, and the values are their frequencies\n",
        "    :param numpy.ndarray array: intermediary stream as array\n",
        "    :return: frequency table\n",
        "    \"\"\"\n",
        "    #\n",
        "    data = Counter(array)\n",
        "    result = {k: d / len(array) for k, d in data.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "3RmD60uuutRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the find_huffman function, which generates a Huffman code for a given frequency distribution. It's a recursive function that merges the lowest probable pairs."
      ],
      "metadata": {
        "id": "zuYBm62A0iH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_huffman(p: dict) -> dict:\n",
        "    \"\"\"\n",
        "    returns a Huffman code for an ensemble with distribution p\n",
        "    :param dict p: frequency table\n",
        "    :returns: huffman code for each symbol\n",
        "    \"\"\"\n",
        "    # Base case of only two symbols, assign 0 or 1 arbitrarily; frequency does not matter\n",
        "    if len(p) == 2:\n",
        "        return dict(zip(p.keys(), ['0', '1']))\n",
        "\n",
        "    # Create a new distribution by merging lowest probable pair\n",
        "    p_prime = p.copy()\n",
        "    a1, a2 = lowest_prob_pair(p)\n",
        "    p1, p2 = p_prime.pop(a1), p_prime.pop(a2)\n",
        "    p_prime[a1 + a2] = p1 + p2\n",
        "\n",
        "    # Recurse and construct code on new distribution\n",
        "    c = find_huffman(p_prime)\n",
        "    ca1a2 = c.pop(a1 + a2)\n",
        "    c[a1], c[a2] = ca1a2 + '0', ca1a2 + '1'\n",
        "\n",
        "    return c"
      ],
      "metadata": {
        "id": "vFcgjX0uuxgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the lowest_prob_pair helper function, used by find_huffman to identify the two symbols with the lowest probabilities in a frequency distribution."
      ],
      "metadata": {
        "id": "JOnFdt3O0nWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lowest_prob_pair(p):\n",
        "    # Return pair of symbols from distribution p with lowest probabilities\n",
        "    sorted_p = sorted(p.items(), key=lambda x: x[1])\n",
        "    return sorted_p[0][0], sorted_p[1][0]"
      ],
      "metadata": {
        "id": "GV7xaww7u18Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the standard quantization tables for JPEG compression: QTY for luminance (Y channel) and QTC for chrominance (Cb and Cr channels)."
      ],
      "metadata": {
        "id": "1QcO6RDwxK4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QTY = np.array([[16, 11, 10, 16, 24, 40, 51, 61],  # luminance quantization table\n",
        "                [12, 12, 14, 19, 26, 48, 60, 55],\n",
        "                [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "                [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "                [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "                [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "                [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "                [72, 92, 95, 98, 112, 100, 103, 99]])\n",
        "\n",
        "QTC = np.array([[17, 18, 24, 47, 99, 99, 99, 99],  # chrominance quantization table\n",
        "                [18, 21, 26, 66, 99, 99, 99, 99],\n",
        "                [24, 26, 56, 99, 99, 99, 99, 99],\n",
        "                [47, 66, 99, 99, 99, 99, 99, 99],\n",
        "                [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "                [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "                [99, 99, 99, 99, 99, 99, 99, 99],\n",
        "                [99, 99, 99, 99, 99, 99, 99, 99]])"
      ],
      "metadata": {
        "id": "Uw_9_hNWvIwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines the rgb_to_ycbcr function, which converts an image from BGR color space to YCbCr color space using the BT.601 standard formulas. This is a crucial step in JPEG as it separates luminance from chrominance."
      ],
      "metadata": {
        "id": "CvljKIdD0z_M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cc5fd2b"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def rgb_to_ycbcr(image_bgr: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Converts an image from BGR color space to YCbCr color space using\n",
        "    mathematical formulas (BT.601 standard).\n",
        "    Assumes the input image is in BGR format (common for OpenCV).\n",
        "\n",
        "    Args:\n",
        "        image_bgr (np.ndarray): The input image in BGR format (dtype=uint8).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The image converted to YCbCr format (dtype=uint8).\n",
        "    \"\"\"\n",
        "    # Convert to float for calculations\n",
        "    bgr_float = image_bgr.astype(np.float32)\n",
        "    B = bgr_float[:, :, 0]\n",
        "    G = bgr_float[:, :, 1]\n",
        "    R = bgr_float[:, :, 2]\n",
        "\n",
        "    # YCbCr conversion formulas (ITU-R BT.601 coefficients, full range 0-255)\n",
        "    Y  = (0.299   * R + 0.587   * G + 0.114   * B)\n",
        "    Cb = (-0.168736 * R - 0.331264 * G + 0.500   * B + 128)\n",
        "    Cr = (0.500   * R - 0.418688 * G - 0.081312 * B + 128)\n",
        "\n",
        "    # Stack channels and clip to [0, 255] range\n",
        "    ycbcr_image = np.stack([Y, Cb, Cr], axis=-1)\n",
        "    ycbcr_image = np.clip(ycbcr_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return ycbcr_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a comprehensive cell that performs the main JPEG compression steps:\n",
        "\n",
        "\n",
        "*   Reads the original image and converts it to YCbCr.\n",
        "*   Separates Y, Cb, Cr channels and subtracts 128 (level shifting).\n",
        "\n",
        "\n",
        "*   Performs 4:2:2 chrominance subsampling.\n",
        "\n",
        "\n",
        "*   Pads channels to be multiples of windowSize (8x8 blocks).\n",
        "\n",
        "*   Applies Discrete Cosine Transform (DCT) to 8x8 blocks of each channel.\n",
        "\n",
        "\n",
        "\n",
        "*   Quantizes the DCT coefficients using QTY and QTC.\n",
        "\n",
        "\n",
        "*   Performs zigzag scanning on the quantized blocks.\n",
        "\n",
        "\n",
        "*   Applies run-length encoding (run_length_encoding).\n",
        "\n",
        "\n",
        "*   Generates Huffman frequency tables (get_freq_dict).\n",
        "\n",
        "*   Creates Huffman codes (find_huffman).\n",
        "\n",
        "\n",
        "\n",
        "*   Encodes the data into bitstreams and writes them to a file named \"CompressedImage.asfh\".\n",
        "\n",
        "*   Calculates and prints the compression ratio."
      ],
      "metadata": {
        "id": "fp9ZMTKT1BA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jpeg_compress(img_bgr, QTY, QTC, windowSize):\n",
        "    # read image\n",
        "    img = rgb_to_ycbcr(img_bgr)\n",
        "    width = len(img[0])\n",
        "    height = len(img)\n",
        "    y = np.zeros((height, width), np.float32) + img[:, :, 0]\n",
        "    cb = np.zeros((height, width), np.float32) + img[:, :, 1]\n",
        "    cr = np.zeros((height, width), np.float32) + img[:, :, 2]\n",
        "    # size of the image in bits before compression\n",
        "    totalNumberOfBitsWithoutCompression = len(y) * len(y[0]) * 8 + len(cb) * len(cb[0]) * 8 + len(cr) * len(cr[0]) * 8\n",
        "    # channel values should be normalized, hence subtract 128\n",
        "    y = y - 128\n",
        "    cr = cr - 128\n",
        "    cb = cb - 128\n",
        "    # 4: 2: 2 subsampling is used # another subsampling scheme can be used\n",
        "    # thus chrominance channels should be sub-sampled\n",
        "    # define subsampling factors in both horizontal and vertical directions\n",
        "    SSH, SSV = 2, 2\n",
        "    # filter the chrominance channels using a 2x2 averaging filter # another type of filter can be used\n",
        "    crf = cv2.boxFilter(cr, ddepth=-1, ksize=(2, 2))\n",
        "    cbf = cv2.boxFilter(cb, ddepth=-1, ksize=(2, 2))\n",
        "    crSub = crf[::SSV, ::SSH]\n",
        "    cbSub = cbf[::SSV, ::SSH]\n",
        "\n",
        "    # check if padding is needed,\n",
        "    # if yes define empty arrays to pad each channel DCT with zeros if necessary\n",
        "    yWidth, yLength = ceil(len(y[0]) / windowSize) * windowSize, ceil(len(y) / windowSize) * windowSize\n",
        "    if (len(y[0]) % windowSize == 0) and (len(y) % windowSize == 0):\n",
        "        yPadded = y.copy()\n",
        "    else:\n",
        "        yPadded = np.zeros((yLength, yWidth))\n",
        "        for i in range(len(y)):\n",
        "            for j in range(len(y[0])):\n",
        "                yPadded[i, j] += y[i, j]\n",
        "\n",
        "    # chrominance channels have the same dimensions, meaning both can be padded in one loop\n",
        "    cWidth, cLength = ceil(len(cbSub[0]) / windowSize) * windowSize, ceil(len(cbSub) / windowSize) * windowSize\n",
        "    if (len(cbSub[0]) % windowSize == 0) and (len(cbSub) % windowSize == 0):\n",
        "        crPadded = crSub.copy()\n",
        "        cbPadded = cbSub.copy()\n",
        "    # since chrominance channels have the same dimensions, one loop is enough\n",
        "    else:\n",
        "        crPadded = np.zeros((cLength, cWidth))\n",
        "        cbPadded = np.zeros((cLength, cWidth))\n",
        "        for i in range(len(crSub)):\n",
        "            for j in range(len(crSub[0])):\n",
        "                crPadded[i, j] += crSub[i, j]\n",
        "                cbPadded[i, j] += cbSub[i, j]\n",
        "\n",
        "    # get DCT of each channel\n",
        "    # define three empty matrices\n",
        "    yDct, crDct, cbDct = np.zeros((yLength, yWidth)), np.zeros((cLength, cWidth)), np.zeros((cLength, cWidth))\n",
        "\n",
        "    # number of iteration on x axis and y axis to calculate the luminance cosine transform values\n",
        "    hBlocksForY = int(len(yDct[0]) / windowSize)  # number of blocks in the horizontal direction for luminance\n",
        "    vBlocksForY = int(len(yDct) / windowSize)  # number of blocks in the vertical direction for luminance\n",
        "    # number of iteration on x axis and y axis to calculate the chrominance channels cosine transforms values\n",
        "    hBlocksForC = int(len(crDct[0]) / windowSize)  # number of blocks in the horizontal direction for chrominance\n",
        "    vBlocksForC = int(len(crDct) / windowSize)  # number of blocks in the vertical direction for chrominance\n",
        "\n",
        "    # define 3 empty matrices to store the quantized values\n",
        "    yq, crq, cbq = np.zeros((yLength, yWidth)), np.zeros((cLength, cWidth)), np.zeros((cLength, cWidth))\n",
        "    # and another 3 for the zigzags\n",
        "    yZigzag = np.zeros(((vBlocksForY * hBlocksForY), windowSize * windowSize))\n",
        "    crZigzag = np.zeros(((vBlocksForC * hBlocksForC), windowSize * windowSize))\n",
        "    cbZigzag = np.zeros(((vBlocksForC * hBlocksForC), windowSize * windowSize))\n",
        "\n",
        "    yCounter = 0\n",
        "    for i in range(vBlocksForY):\n",
        "        for j in range(hBlocksForY):\n",
        "            yDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = cv2.dct(\n",
        "                yPadded[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            yq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = np.ceil(\n",
        "                yDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] / QTY)\n",
        "            yZigzag[yCounter] += zigzag(\n",
        "                yq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            yCounter += 1\n",
        "    yZigzag = yZigzag.astype(np.int16)\n",
        "\n",
        "    # either crq or cbq can be used to compute the number of blocks\n",
        "    cCounter = 0\n",
        "    for i in range(vBlocksForC):\n",
        "        for j in range(hBlocksForC):\n",
        "            crDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = cv2.dct(\n",
        "                crPadded[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            crq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = np.ceil(\n",
        "                crDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] / QTC)\n",
        "            crZigzag[cCounter] += zigzag(\n",
        "                crq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            cbDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = cv2.dct(\n",
        "                cbPadded[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            cbq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] = np.ceil(\n",
        "                cbDct[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize] / QTC)\n",
        "            cbZigzag[cCounter] += zigzag(\n",
        "                cbq[i * windowSize: i * windowSize + windowSize, j * windowSize: j * windowSize + windowSize])\n",
        "            cCounter += 1\n",
        "    crZigzag = crZigzag.astype(np.int16)\n",
        "    cbZigzag = cbZigzag.astype(np.int16)\n",
        "\n",
        "    # find the run length encoding for each channel\n",
        "    # then get the frequency of each component in order to form a Huffman dictionary\n",
        "    yEncoded = run_length_encoding(yZigzag)\n",
        "    yFrequencyTable = get_freq_dict(yEncoded)\n",
        "    yHuffman = find_huffman(yFrequencyTable)\n",
        "\n",
        "    crEncoded = run_length_encoding(crZigzag)\n",
        "    crFrequencyTable = get_freq_dict(crEncoded)\n",
        "    crHuffman = find_huffman(crFrequencyTable)\n",
        "\n",
        "    cbEncoded = run_length_encoding(cbZigzag)\n",
        "    cbFrequencyTable = get_freq_dict(cbEncoded)\n",
        "    cbHuffman = find_huffman(cbFrequencyTable)\n",
        "\n",
        "    # calculate the number of bits to transmit for each channel\n",
        "    # and write them to an output file\n",
        "    file = open(\"CompressedImage.bin\", \"w\")\n",
        "    yBitsToTransmit = str()\n",
        "    for value in yEncoded:\n",
        "        yBitsToTransmit += yHuffman[value]\n",
        "\n",
        "    crBitsToTransmit = str()\n",
        "    for value in crEncoded:\n",
        "        crBitsToTransmit += crHuffman[value]\n",
        "\n",
        "    cbBitsToTransmit = str()\n",
        "    for value in cbEncoded:\n",
        "        cbBitsToTransmit += cbHuffman[value]\n",
        "\n",
        "    if file.writable():\n",
        "        file.write(yBitsToTransmit + \"\\n\" + crBitsToTransmit + \"\\n\" + cbBitsToTransmit)\n",
        "    file.close()\n",
        "\n",
        "    print(\"\\nY Bitstream (first 100 chars):\", yBitsToTransmit[:100])\n",
        "    print(\"Cr Bitstream (first 100 chars):\", crBitsToTransmit[:100])\n",
        "    print(\"Cb Bitstream (first 100 chars):\", cbBitsToTransmit[:100])\n",
        "\n",
        "    totalNumberOfBitsAfterCompression = len(yBitsToTransmit) + len(crBitsToTransmit) + len(cbBitsToTransmit)\n",
        "    print(\n",
        "        \"Compression Ratio is \" + str(\n",
        "            np.round(totalNumberOfBitsWithoutCompression / totalNumberOfBitsAfterCompression, 1)))\n",
        "\n",
        "    return {\n",
        "        'yHuffman': yHuffman,\n",
        "        'crHuffman': crHuffman,\n",
        "        'cbHuffman': cbHuffman,\n",
        "        'height': height,\n",
        "        'width': width,\n",
        "        'hBlocksForY': hBlocksForY,\n",
        "        'vBlocksForY': vBlocksForY,\n",
        "        'hBlocksForC': hBlocksForC,\n",
        "        'vBlocksForC': vBlocksForC,\n",
        "        'yLength': yLength,\n",
        "        'yWidth': yWidth,\n",
        "        'cLength': cLength,\n",
        "        'cWidth': cWidth,\n",
        "        'SSH': SSH,\n",
        "        'SSV': SSV,\n",
        "        'windowSize': windowSize\n",
        "    }"
      ],
      "metadata": {
        "id": "8FMibr0oZzDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calls the jpeg_compress function to compress the input image"
      ],
      "metadata": {
        "id": "3PxBaAdlUa69"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3e8146c",
        "outputId": "adbb6b83-a31d-4494-d3a0-dbf1ae9cdd63"
      },
      "source": [
        "# Define the window size for block processing\n",
        "windowSize = 8\n",
        "\n",
        "# Check if imgOriginal is available before compression\n",
        "if imgOriginal is not None:\n",
        "    # Call the jpeg_compress function\n",
        "    compression_results = jpeg_compress(imgOriginal, QTY, QTC, windowSize)\n",
        "\n",
        "    # Unpack the results into global variables\n",
        "    globals().update(compression_results)\n",
        "\n",
        "    print(\"JPEG compression completed and parameters stored\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: No image loaded for compression. Please ensure 'mandril_color.jpg' is present or upload an image.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Y Bitstream (first 100 chars): 1010100100101011111101001110101000101010111011111010101111111000111101111011110111111010011101110110\n",
            "Cr Bitstream (first 100 chars): 1110011000010010010011101100000011110111100100100110001011110111011011110000110111111111001001000011\n",
            "Cb Bitstream (first 100 chars): 1101000010011110010001101010000111111110001101000100111100111110011110100111111110011000111010100110\n",
            "Compression Ratio is 8.1\n",
            "JPEG compression completed and parameters stored\n"
          ]
        }
      ]
    }
  ]
}